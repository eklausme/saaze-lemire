---
date: "2007-10-16 12:00:00"
title: "What happens after a technological singularity?"
---


<img decoding="async" src="http://farm1.static.flickr.com/49/112475613_276eec40a1_m.jpg" /><br/><small>([source](http://www.flickr.com/photos/gi/))</small>

A [technological singularity](https://en.wikipedia.org/wiki/Technological_singularity) is a rapid sequence of technological changes tearing apart our society. For example, imagine we can create smarter-than-human-beings machine. Suppose that, in turn, these machines can create other machines that are even smarter than they are. If the timing is just right, you could get infinite intelligence in a finite time. Of course, a technological singularity does not need to be so drastic. It suffices that we exceed the speed at which most human beings can adapt.

My own definition of a technological singularity is the achievement of such a high level of sophistication, that, as far as human beings are concerned, technological progress becomes irrelevant. It could be that we have such an advanced technology that our brain cannot even comprehend progress. Or maybe, we are all trying to kill each others so that the insanity can stop. Or it could happen on the day spammers find a way to get spam directly in our brains and we are all buying pills to get our penises to be longer.

It is hard to tell if such a singularity is a distinct possibility. For example, it could become increasingly expensive to improve our technological sophistication faster. One limit is the size of our brain. __Your brain has a limited memory and processing speed.__ But we could possibly expand our brain or replace it with better hardware.

(As I [said before](/lemire/blog/2007/09/10/machine-smarter-than-naked-or-assisted-human-being/), I do not care for AI. I do not want my laptop to be talking back to me. But I would not mind replacing my brain with a piece of hardware that gives me a photographic memory and twice the processing speed.)

For fun, assume that a technological singularity does happen. It may not be a catastrophe. For example, maybe we have the technology to keep us all alive nearly forever and in a quasi-paradise. What happens next? Clearly, our technology cannot improve further, and even if does, nobody cares.

My own prediction is that some strong religious figure would emerge and people would become highly spiritual. Science and technology would be frowned upon. It could even be that we would go back to a medieval state.

See also my posts [Duck Typing, Artificial Intelligence and Philosophy](/lemire/blog/2007/01/27/duck-typing-artificial-intelligence-and-philosophy/), [The Big Bang is Intelligent](/lemire/blog/2007/02/02/the-big-bang-is-intelligent/), and [How artificial intelligences are already at war with us](/lemire/blog/2007/02/16/how-artificial-intelligences-are-already-at-war-with-us/).

