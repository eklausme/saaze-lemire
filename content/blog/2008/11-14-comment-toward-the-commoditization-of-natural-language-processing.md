---
date: "2008-11-14 12:00:00"
title: "Toward the Commoditization of Natural Language Processing"
index: false
---

[3 thoughts on &ldquo;Toward the Commoditization of Natural Language Processing&rdquo;](/lemire/blog/2008/11-14-toward-the-commoditization-of-natural-language-processing)

<ol class="comment-list">
<li id="comment-50257" class="comment even thread-even depth-1">
<div class="comment-author vcard">
<img alt src="https://secure.gravatar.com/avatar/988ac6d9ab01c62c26ca83981a0e5e9a?s=56&#038;d=mm&#038;r=g" srcset="https://secure.gravatar.com/avatar/988ac6d9ab01c62c26ca83981a0e5e9a?s=112&#038;d=mm&#038;r=g 2x" class="avatar avatar-56 photo" height="56" width="56" decoding="async" /> <b class="fn">Kevembuangga</b> <span class="says">says:</span> </div>
<div class="comment-metadata"><time datetime="2008-11-15T12:39:46+00:00">November 15, 2008 at 12:39 pm</time></a> </div>
<div class="comment-content">
<p>Alas this is still grunt work driven by the &ldquo;competition imperative&rdquo;, typical of what I criticised as <a href="https://lemire.me/blog/2008/10/27/the-future-of-innovation-is-in-software/#comment-50246" rel="nofollow">â€œnifty promising resultsâ€</a> for another domain (software) but the basic flaw is the same and has been well stated 25 years ago by Marcel Schoppers:<br/>
<a href="https://groups.google.com/forum/" rel="nofollow">&ldquo;If AI has made little obvious progress it may be because we are too busy<br/>
trying to produce useful systems before we know how they should work.&rdquo;</a></p>
<p>As you say Daniel: <i>Being sane, most researchers work on problem where it is plausible they can make some progress in a few months by working in small increments each day.</i><br/>
But THIS is &ldquo;the problem&rdquo;, not the way to a solution and it stems directly from the rules of publishing (irrespective of the &ldquo;goodness&rdquo; of peer reviewing) and from the need for a career.<br/>
Early scientists from Newton to may be somewhere in the middle of XIX century didn&rsquo;t have so much pressing economic constraints and were able to speculate more freely on abstract questions, not El Naschie way of course, LOL (though&#8230; Newton delved in many kooky topics&#8230;).</p>
</div>
</li>
<li id="comment-50258" class="comment byuser comment-author-lemire bypostauthor odd alt thread-odd thread-alt depth-1">
<div class="comment-author vcard">
<img alt src="https://secure.gravatar.com/avatar/2ca999bef9535950f5b84281a4dab006?s=56&#038;d=mm&#038;r=g" srcset="https://secure.gravatar.com/avatar/2ca999bef9535950f5b84281a4dab006?s=112&#038;d=mm&#038;r=g 2x" class="avatar avatar-56 photo" height="56" width="56" decoding="async" /> <b class="fn"><a href="https://lemire.me/blog/" class="url" rel="ugc">Daniel Lemire</a></b> <span class="says">says:</span> </div>
<div class="comment-metadata"><time datetime="2008-11-15T12:47:31+00:00">November 15, 2008 at 12:47 pm</time></a> </div>
<div class="comment-content">
<p>Thankfully, there are exceptions, such as Peter Turney&#8230;</p>
</div>
</li>
<li id="comment-50262" class="comment even thread-even depth-1">
<div class="comment-author vcard">
<img alt src="https://secure.gravatar.com/avatar/eb2d858a6ccea692bf677ad2c66623ad?s=56&#038;d=mm&#038;r=g" srcset="https://secure.gravatar.com/avatar/eb2d858a6ccea692bf677ad2c66623ad?s=112&#038;d=mm&#038;r=g 2x" class="avatar avatar-56 photo" height="56" width="56" loading="lazy" decoding="async" /> <b class="fn">Peter Turney</b> <span class="says">says:</span> </div>
<div class="comment-metadata"><time datetime="2008-11-17T16:03:23+00:00">November 17, 2008 at 4:03 pm</time></a> </div>
<div class="comment-content">
<p>Daniel, thanks for your kind words. My algorithm is only a small increment, as Kevembuangga notes. I believe that science always proceeds by small increments. I give an informal description of the paper here.</p>
</div>
</li>
</ol>
